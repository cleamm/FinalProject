2024/7/2
1. 영화 관련 데이터 파일 업로드
2. chatgpt의 도움으로 시험 삼아 영화 대화 파일 1개로 모델을 만들어봄
3. 처음 CPU로 돌린 결과 10-15분 걸림
4. gpu로 돌린 결과 5초

2024/7/5
1. 87000의 대화로 모델을 만들어 봄
2. 5분정도 걸림
3. 300 epoch , batch=15,  Loss=0.005700
4. 299 epoch, batch=5,   Loss=0.001500

tokenizer = 'gpt2'
model = GPT2LMHeadModel.from_pretrained('gpt2')

결과
1)                                                 2)
Response: 추천 해 줄 영화 있어?
2집 근처에는 병원 �
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

답변은 여전히 안됨
gpt 3.5 모델을 사용하거나, 데이터를 어떻게 더 전처리 하는지 알아야 할 거 같음

Response: 아니 어제 머했냐고 20분 거리에 있어.
2집 

2024/7/8
KoGPT를 이용해서 만들어좀
걸린 시간 4시간

과정은 따로 설명하겠음..

결과
user > 범죄도시 재밌냐?
Chatbot > 나 그런 거 안 봤어
user > 범죄 도시 같은 영화 추천 해줘
Chatbot > 나 범죄 도시  제일 최근에 본 영화야
user > 다른 영화 없어?
Chatbot > 나 외국 영화 좋아하잖아~
user > 한국영화는 안 좋아하냐?
Chatbot > 응응 영화가 제일 재밌어
user > 어제는 모 했어?
Chatbot > 오늘부터인가
user > 아침 밥은 먹었어?
Chatbot > 응 근데 나 오메가쓰리 많이 먹어서 요즘 오메가쓰리 많이 먹는 중
user > 개킹받네
Chatbot > 그럼 그 강아지 쌉가능
user > 내놔 임마
Chatbot > 그럼 너가 대신 들어가 줄게
user > ㅋㅋㅋ
Chatbot > 아유 키키 그래도 이번 추석은 잘 버틸 수 있겠어