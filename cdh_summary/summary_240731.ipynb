{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/seujung/KoBART-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a1e24e074643c1a94d766984a68b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe814b0b5b94e9aac41e9b0e8a3241e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: summarize:  Your long text here that you want to summarize. Use the weekly Newsquiz to test your knowledge of stories you read.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Initialize the BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def summarize_text(text, max_length=150, min_length=30, length_penalty=2.0, num_beams=4):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty, num_beams=num_beams, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "text = \"\"\"\n",
    "Your long text here that you want to summarize.\n",
    "\"\"\"\n",
    "summary = summarize_text(text)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023b46f7f6bb45a799b14aa2fb3d578c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ee0c9c39134e639d3637e85e8d3411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbece9ffc0c4c22a6093e2b90dfa93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872b5a002c2d40e98ea241d6ec68e002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de5b49ab259437484dadb7e441fcbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/495M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"gogamza/kobart-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartModel(\n",
       "  (shared): Embedding(30000, 768, padding_idx=3)\n",
       "  (encoder): BartEncoder(\n",
       "    (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x BartEncoderLayer(\n",
       "        (self_attn): BartSdpaAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): BartDecoder(\n",
       "    (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x BartDecoderLayer(\n",
       "        (self_attn): BartSdpaAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): BartSdpaAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "윤석열 대통령은 31일 고용노동부 장관 후보에 김문수 경제사회노동위원장을 지명했다.\n",
    "\n",
    "정진석 대통령실 비서실장은 이날 용산 대통령실에서 브리핑을 열어 이같이 발표했다.\n",
    "\n",
    "정 실장은 “고용노동계의 현안이 산적해 있는 시점에 노동 현장과 입법·행정부를 두루 경험한 후보자야말로 다양한 구성원들과의 대화와 타협을 바탕으로 노동 개혁 과제를 완수할 수 있는 적임자로 생각된다”고 말했다.\n",
    "\n",
    "김 노동부 장관 내정자는 노동운동가 출신이다. 1996년 신한국당으로 국회에 입성 15~17대 국회의원을 지냈다. 2006∼2014년 경기도지사를 지냈고 박근혜 전 대통령 탄핵 정국에서는 보수단체의 태극기 집회를 옹호하기도 했다.\n",
    "\n",
    "김 내정자는 정 실장의 발표가 끝난 뒤 “부족한 점이 많은 사람임에도 불구하고 대통령께서 고용노동부 장관 후보자로 지명하셨다”며 “제가 부족한 만큼 한국노총을 비롯한 노동계와 경총을 비롯한 사용자 단체, 국회와 노동 관련 학계·언론계의 말씀을 늘 경청하겠다”고 밝혔다.\n",
    "\n",
    "김 내정자는 “윤석열 대통령의 법치주의 노동 개혁은 지난 2년간 상당한 성과를 거둬 노사 분규로 인한 노동 손실일수가 대폭 감소했다”면서도 “노동 개혁의 또 다른 과제인 노동 약자 보호는 복잡하고 어려운 문제”라고 했다. 이어 “5인 미만 사업장이나 영세 중소기업 비조직 노동자들도 결혼해서 자녀를 가질 수 있는 소박한 꿈을 이룰 수 있도록 정부가 나서서 적극 도와드려야 하겠다”며 “윤 대통령의 노동 개혁이 성공해 노사정이 모두 행복한 대한민국을 만드는 데 최선을 다하겠다”고 덧붙였다.\n",
    "\n",
    "윤 대통령은 이날 이진숙 방송통신위원장과 김병환 금융위원장의 임명안을 재가했다. 또 방송통신위원회 상임위원으로 김태규 국민권익위원회 부위원장을, 주일본대사에 박철희 국립외교원장, 주호주대사에 심승섭 전 해군참모총장, 국립외교원장 후임에 최형찬 주네덜란드 대사를 임명했다.\n",
    "\"\"\"\n",
    "\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
    "res = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'윤석열 대통령은 31일 고용노동부 장관 후보에 노동 현장과 입법·행정부를 두루 경험한 김문수 경제사회노동위원장을 지명했다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch==2.0.1\n",
    "# transformers==4.32.1\n",
    "# tokenizers==0.13.3\n",
    "# lightning==2.0.8\n",
    "# streamlit==1.26.0\n",
    "# wandb==0.15.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tokenizers==0.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb==0.15.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
